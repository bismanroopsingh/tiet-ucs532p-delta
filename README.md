Computer Vision for Fabric Defect DetectionUnsupervised Texture Analysis FrameworkI. Theoretical Foundation (The "Math Engines")This research era focused on creating mathematical descriptors that mimic the human ability to "feel" a surface through pixel intensities.1. Gray-Level Co-occurrence Matrix (GLCM)Source: Haralick, R. M. (1973): “Textural Features for Image Classification.”Concept: Haralick established that texture is defined by the spatial relationship between pixels rather than individual intensities. The GLCM tracks how often pairs of pixels occur at specific distances and orientations.Fabric Application:Contrast: Identifies sharp changes in pixel intensity, revealing rough patches or physical surface damage.Entropy: Measures texture randomness. Healthy fabric maintains a low-entropy predictable pattern; a defect causes an entropy surge that flags the anomaly.2. Local Binary Patterns (LBP)Source: Ojala, T., et al. (2002): “Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns.”Concept: LBP compares a center pixel to its neighbors (assigning '1' if the neighbor is brighter and '0' if darker), creating an 8-bit string for every pixel.Fabric Application: Ojala’s refinement allows for rotation invariance, meaning the system can detect defects (like slubs or knots) regardless of how the fabric is oriented on the loom.3. Gabor FiltersSource: Kumar, A., & Pang, G. K. (2002): “Defect detection in textured materials using Gabor filters.”Concept: Gabor filters are frequency and orientation selective, acting as "mathematical tuning forks."Fabric Application: Fabric is a grid of horizontal (weft) and vertical (warp) threads. Filters are tuned to the frequency of the weave; if a thread is missing, the "resonance" drops, allowing for structural defect identification.4. Unsupervised Anomaly DetectionSource: Zhou, H., et al. (2022): “One-Class Model for Fabric Defect Detection.”Concept: Because defects are rare and unpredictable, Zhou argued for a One-Class SVM approach.Application: The model is trained exclusively on "perfect" fabric images to establish a mathematical boundary (hypersphere). Anything falling outside this boundary is automatically classified as an anomaly.II. Comparative Analysis of DatasetsDatasetTotal ImagesDefect-Free ImagesResolutionPrimary BenefitAITEX (AFID)2451404096 × 256High-res images allow for thousands of patches from minimal files.MVTec AD5,354~3,600VariableIndustry gold standard for anomaly detection benchmarks.Ten Fabrics (TFD)3,0002,257256 × 256Large variety of 27 different defect types for testing.TILDA3,200Variable768 × 512Includes rotations/lighting changes for feature robustness.Lusitano (2024)32,0006,0004096 × 1024Modern large-scale dataset for industrial line cameras.Why AITEX (AFID) was SelectedWhile other datasets offer higher volume, AITEX aligns with our patch-based unsupervised approach:High Spatial Density: A single 4096 × 256 image yields over 1,000 unique 32x32 training patches. This allows us to train a robust One-Class SVM with only 30–50 full images.Texture Complexity: Unlike general benchmarks, AITEX is textile-specific, featuring plain and twill weaves ideal for Gabor and LBP validation.Benchmark Credibility: As a widely accepted standard, it ensures our results are comparable to state-of-the-art research.III. Methodology: The 3-Step WorkflowStep 1: Windowing (The Scanner)The system employs a Sliding Window technique (32×32 pixels) to examine the fabric patch-by-patch. This ensures real-time processing and precise localization without overwhelming the hardware.Step 2: Feature Extraction (The Math Engines)LBP: Detects surface irregularities like knots and slubs.GLCM: Monitors smoothness through Contrast and Entropy.Gabor Filters: Analyzes directional weaves to find missing or misaligned threads.Step 3: Anomaly Detection (The Decision)A One-Class SVM learns the mathematical boundary of "Normal" using only the perfect fabric examples. Any texture vector falling outside this boundary is flagged.IV. Technical AdvantagesSmall Data Requirement: Only 30–50 images of perfect fabric are required for training, significantly reducing the data collection burden.Explainable Results: Unlike "black box" neural networks, the system can state precisely why a patch was rejected (e.g., "Contrast exceeded threshold").Real-Time Speed: Mathematically efficient algorithms run on standard CPUs or embedded devices without the need for expensive GPUs.
